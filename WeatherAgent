# Import relevant functionality
import getpass
import os
from langchain.chat_models import init_chat_model
from langchain_tavily import TavilySearch
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent

# Set up API key
if not os.environ.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter API key for OpenAI: ")

# Initialize tools
search = TavilySearch(max_results=2)
tools = [search]

# Test search functionality
search_results = search.invoke("What is the weather in SF")
print(search_results)

# Initialize model
model = init_chat_model("gpt-4.1", model_provider="openai")

# Create the agent with memory
memory = MemorySaver()
agent_executor = create_react_agent(model, tools, checkpointer=memory)

# Test model with tools
query = "Search for the weather in SF"
response = model_with_tools.invoke([{"role": "user", "content": query}])
print(f"Message content: {response.text()}\n")
print(f"Tool calls: {response.tool_calls}")
